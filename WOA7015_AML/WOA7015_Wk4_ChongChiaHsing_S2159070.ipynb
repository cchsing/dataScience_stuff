{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1X74lJz_WtVzLE7wovpYMDK3WI0Z0qphr","timestamp":1668161527785}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Cw5hkuTyx3VO"},"source":["# Welcome to WOA7015 Advance Machine Learning Lab - Week 4\n","This code is generated for the purpose of WOA7015 module.\n","The code is available in github https://github.com/shiernee/Advanced_ML \n"]},{"cell_type":"markdown","metadata":{"id":"INxzH5Bqw5dq"},"source":["## 1.0 Effect of weight and bias to sigmoid function\n","This is the code to generate the figure in slide 6"]},{"cell_type":"markdown","metadata":{"id":"2HctFBauH47o"},"source":["#### 1.1 Effect of weight on sigmoid function"]},{"cell_type":"code","metadata":{"id":"ah7KAg-fsGWY"},"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import imageio\n","\n","# create sigmoid function\n","f = lambda x, w, b: 1/(1 + np.exp(-(w*x + b)))\n","\n","x = np.arange(-10, 10, 0.01).reshape([-1, 1])\n","\n","# effect of weight on sigmoid function\n","filenames = []\n","for i in np.arange(1, 5, 0.1):\n","  w = np.ones([1, 1]) * i * 0.5\n","  b = np.ones([1, 1]) * 0\n","\n","  plt.plot(x, f(x, w, b))\n","  plt.title('w = %0.1f' % i)\n","  plt.grid()\n","  plt.savefig('w %0.1f.png' % i)\n","  plt.close()\n","  filenames.append('w %0.1f.png' % i)\n","\n","# Build GIF\n","with imageio.get_writer('w_mygif.gif', mode='I') as writer:\n","    for filename in filenames:\n","        image = imageio.imread(filename)\n","        writer.append_data(image)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JYbm63A9H91J"},"source":["#### 1.1 Effect of bias on sigmoid function"]},{"cell_type":"code","metadata":{"id":"s1QreLFgHyIi"},"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import imageio\n","\n","# create sigmoid function\n","f = lambda x, w, b: 1/(1 + np.exp(-(w*x + b)))\n","\n","x = np.arange(-10, 10, 0.01).reshape([-1, 1])\n","\n","# effect of bias on sigmoid function\n","filenames = []\n","for i in np.arange(1, 5, 0.1):\n","  w = np.ones([1, 1])\n","  b = np.ones([1, 1])* i\n","\n","  plt.plot(x, f(x, w, b))\n","  plt.title('b = %0.1f' % i)\n","  plt.grid()\n","  plt.savefig('b %0.1f.png' % i)\n","  plt.close()\n","  filenames.append('b %0.1f.png' % i)\n","\n","# Build GIF\n","with imageio.get_writer('b_mygif.gif', mode='I') as writer:\n","    for filename in filenames:\n","        image = imageio.imread(filename)\n","        writer.append_data(image)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iXAZiEqSEbDH"},"source":["# 2.0 Logistic Regression\n","\n","In this section, we will learn how to create train a Logistic Regression Model using pytorch. We will use MNIST image, as shown below. <br><br>\n","\n","PyTorch (https://pytorch.org/) is an open source machine learning library based on the Torch library, used for applications such as computer vision and natural language processing, primarily developed by Facebook's AI Research lab. \n","\n","\n","<br>\n","<img src=\"https://raw.githubusercontent.com/shiernee/Advanced_ML/main/Week4/MnistExamples.png\" width=\"512\"/>\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"5NXavLptEdGe"},"source":["# 2.1 import library\n","import torch\n","import torch.nn as nn\n","import torchvision\n","import torchvision.transforms as transforms\n","import numpy as np\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"crKCbRxdFD86"},"source":["#2.2 Set the Hyper-parameters \n","input_size = 28 * 28  # 784\n","num_classes = 10\n","num_epochs = 5\n","batch_size = 100\n","learning_rate = 0.001\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cZXRWEdzFt_Z"},"source":["#2.3 Data loader\n","# MNIST dataset (images and labels)\n","train_dataset = torchvision.datasets.MNIST(root='../../data', \n","                                           train=True, \n","                                           transform=transforms.ToTensor(),\n","                                           download=True)\n","\n","test_dataset = torchvision.datasets.MNIST(root='../../data', \n","                                          train=False, \n","                                          transform=transforms.ToTensor())\n","\n","# Data loader (input pipeline)\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n","                                           batch_size=batch_size, \n","                                           shuffle=True)\n","\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n","                                          batch_size=batch_size, \n","                                          shuffle=False)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":593},"id":"PCMGIa6ZLxWX","executionInfo":{"status":"ok","timestamp":1669003937075,"user_tz":-480,"elapsed":534,"user":{"displayName":"CHIA HSING CHONG","userId":"13471313610066442776"}},"outputId":"77f0d586-3f9f-4845-a4b9-3f03d3653de4"},"source":["# 2.3.1 Check data \n","print(train_dataset)\n","print('----------------')\n","print(test_dataset)\n","print()\n","\n","import matplotlib.pyplot as plt\n","print('training data shape: ', train_dataset.data.shape)\n","n = np.random.randint(0, 60000)\n","plt.imshow(train_dataset.data[n])\n","plt.title(f'n = %d label = %d' % (n, train_dataset.train_labels[n].numpy()))\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset MNIST\n","    Number of datapoints: 60000\n","    Root location: ../../data\n","    Split: Train\n","    StandardTransform\n","Transform: ToTensor()\n","----------------\n","Dataset MNIST\n","    Number of datapoints: 10000\n","    Root location: ../../data\n","    Split: Test\n","    StandardTransform\n","Transform: ToTensor()\n","\n","training data shape:  torch.Size([60000, 28, 28])\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:65: UserWarning: train_labels has been renamed targets\n","  warnings.warn(\"train_labels has been renamed targets\")\n"]},{"output_type":"execute_result","data":{"text/plain":["Text(0.5, 1.0, 'n = 43926 label = 7')"]},"metadata":{},"execution_count":47},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"N6ZE4roJF0HA"},"source":["#2.4 Logistic regression model\n","model = nn.Linear(input_size, num_classes)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XXCxm64GH27K"},"source":["#2.5 Cross Entropy Loss \n","# nn.CrossEntropyLoss() computes softmax internally\n","criterion = nn.CrossEntropyLoss()   \n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pm2Q-PDcH34b"},"source":["#2.6 Optimizer Stochastic Gradient Descent \n","optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  \n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4TO7Egs7F2o9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669003978983,"user_tz":-480,"elapsed":37453,"user":{"displayName":"CHIA HSING CHONG","userId":"13471313610066442776"}},"outputId":"a181e706-312d-4ab7-ff96-c07af2399472"},"source":["#2.7 Train the model\n","total_step = len(train_loader)\n","for epoch in range(num_epochs):\n","    for i, (images, labels) in enumerate(train_loader):\n","        # Reshape images to (batch_size, input_size)\n","        images = images.reshape(-1, input_size)\n","        \n","        # Forward pass\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","\n","        # Backward and optimize\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        \n","        if (i+1) % 100 == 0:\n","            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n","                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/5], Step [100/600], Loss: 2.2127\n","Epoch [1/5], Step [200/600], Loss: 2.0888\n","Epoch [1/5], Step [300/600], Loss: 2.0256\n","Epoch [1/5], Step [400/600], Loss: 1.9361\n","Epoch [1/5], Step [500/600], Loss: 1.8750\n","Epoch [1/5], Step [600/600], Loss: 1.8121\n","Epoch [2/5], Step [100/600], Loss: 1.7192\n","Epoch [2/5], Step [200/600], Loss: 1.6593\n","Epoch [2/5], Step [300/600], Loss: 1.6407\n","Epoch [2/5], Step [400/600], Loss: 1.6038\n","Epoch [2/5], Step [500/600], Loss: 1.5125\n","Epoch [2/5], Step [600/600], Loss: 1.4656\n","Epoch [3/5], Step [100/600], Loss: 1.5172\n","Epoch [3/5], Step [200/600], Loss: 1.3261\n","Epoch [3/5], Step [300/600], Loss: 1.3029\n","Epoch [3/5], Step [400/600], Loss: 1.3989\n","Epoch [3/5], Step [500/600], Loss: 1.2512\n","Epoch [3/5], Step [600/600], Loss: 1.1938\n","Epoch [4/5], Step [100/600], Loss: 1.2319\n","Epoch [4/5], Step [200/600], Loss: 1.2853\n","Epoch [4/5], Step [300/600], Loss: 1.1401\n","Epoch [4/5], Step [400/600], Loss: 1.1226\n","Epoch [4/5], Step [500/600], Loss: 1.1503\n","Epoch [4/5], Step [600/600], Loss: 1.0943\n","Epoch [5/5], Step [100/600], Loss: 0.9439\n","Epoch [5/5], Step [200/600], Loss: 1.0625\n","Epoch [5/5], Step [300/600], Loss: 1.0007\n","Epoch [5/5], Step [400/600], Loss: 1.0843\n","Epoch [5/5], Step [500/600], Loss: 1.1202\n","Epoch [5/5], Step [600/600], Loss: 0.9913\n"]}]},{"cell_type":"code","metadata":{"id":"fGO_mdMZF4iS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669000969570,"user_tz":-480,"elapsed":1111,"user":{"displayName":"CHIA HSING CHONG","userId":"13471313610066442776"}},"outputId":"0e9213ad-e07d-4431-98a6-8e3b6e150b5f"},"source":["#2.8 Test the model\n","# In test phase, we don't need to compute gradients (for memory efficiency)\n","with torch.no_grad():\n","    correct = 0\n","    total = 0\n","    for images, labels in test_loader:\n","        images = images.reshape(-1, input_size)\n","        outputs = model(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum()\n","\n","    print('Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy of the model on the 10000 test images: 82.66999816894531 %\n"]}]},{"cell_type":"code","metadata":{"id":"EBEBeGYsF5t-"},"source":["#2.9 Save the model checkpoint\n","torch.save(model.state_dict(), 'model.ckpt')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j6nIkwr2YM9l"},"source":["## Exercise 1 (10%): Create custom loss function\n","In this section, you will need to create our own Cross Entropy loss function and compare with Pytorch's Cross Entropy loss. The objective of this exercise is to enable you to design your own loss function in the future. \n","\n","Follow the steps below:\n","1. Import libraries \n","2. Set hyperparameter\n","3. Data loader \n","4. Initialize Logistic Regression \n","5. Create custom_CrossEntropyLoss class - copy the following code. Your task is to ***code the log_softmax equation in the log_softmax function.*** \n","\n","```\n","#  Custom Loss - Cross Entropy Loss\n","class custom_CrossEntropyLoss(nn.Module):\n","    def __init__(self, weight=None, size_average=True):\n","        super(custom_CrossEntropyLoss, self).__init__()\n"," \n","    def forward(self, inputs, targets, smooth=1):      \n","        num_examples = targets.shape[0]\n","        batch_size = inputs.shape[0]\n","        softmax_outputs = self.log_softmax(inputs)\n","        outputs = softmax_outputs[range(batch_size), targets]        \n","        return -torch.sum(outputs)/num_examples\n","\n","    @staticmethod\n","    def log_softmax(x):\n","      return ### put the log_softmax function here ### \n","```\n","\n","6. Initialize custom_CrossEntropyLoss loss as criterion - copy section 2.5. Replace *nn.CrossEntropyLoss* with *custom_CrossEntropyLoss*\n","7. Train the model, evaluate it on your testing data. Save your model. \n","8. Compare the loss computed from torch and our custom loss.  \n","\n","\n"," 5% will be  given if step 1 - 4 are done correctly <br>\n"," 3% will be  given if step 5-7 is done correctly <br>\n"," 2% will be given if your custom loss and pytorch loss is near zero. "]},{"cell_type":"code","metadata":{"id":"7azur5ciavP2"},"source":["# Step 1 import library\n","import torch\n","import torch.nn as nn\n","import torchvision\n","import torchvision.transforms as transforms\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Step 2 Set the hyperparameters\n","input_size = 28 * 28  \n","num_classes = 10\n","num_epochs = 5\n","batch_size = 100\n","learning_rate = 0.001"],"metadata":{"id":"IKP6TBHgNtUg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Step 3 Data loader\n","# MNIST dataset (images and labels)\n","train_dataset = torchvision.datasets.MNIST(root='../../data', \n","                                           train=True, \n","                                           transform=transforms.ToTensor(),\n","                                           download=True)\n","\n","test_dataset = torchvision.datasets.MNIST(root='../../data', \n","                                          train=False, \n","                                          transform=transforms.ToTensor())\n","\n","# Data loader (input pipeline)\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n","                                           batch_size=batch_size, \n","                                           shuffle=True)\n","\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n","                                          batch_size=batch_size, \n","                                          shuffle=False)\n","train_loader, test_loader"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i0EJvGq9N-3s","executionInfo":{"status":"ok","timestamp":1669007586708,"user_tz":-480,"elapsed":358,"user":{"displayName":"CHIA HSING CHONG","userId":"13471313610066442776"}},"outputId":"05386628-740e-456a-d9ee-8d50c1cd5d3a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(<torch.utils.data.dataloader.DataLoader at 0x7f9ea856ee90>,\n"," <torch.utils.data.dataloader.DataLoader at 0x7f9ea81e16d0>)"]},"metadata":{},"execution_count":136}]},{"cell_type":"code","source":["# Step 4 Initialize Logistic Regression\n","model = nn.Linear(input_size, num_classes)\n","model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S8JYPMnoOACA","executionInfo":{"status":"ok","timestamp":1669007590701,"user_tz":-480,"elapsed":351,"user":{"displayName":"CHIA HSING CHONG","userId":"13471313610066442776"}},"outputId":"3d28b8d5-ea0f-481c-bf03-30cef14eb3cb"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Linear(in_features=784, out_features=10, bias=True)"]},"metadata":{},"execution_count":137}]},{"cell_type":"code","source":["# Step 5 Create custom_CrossEntropyLoss class\n","class custom_CrossEntropyLoss1(nn.Module):\n","    def __init__(self, weight=None, size_average=True):\n","        super(custom_CrossEntropyLoss1, self).__init__()\n","\n","    def forward(self, inputs, targets, smooth=1):      \n","        num_examples = targets.shape[0]\n","        batch_size = inputs.shape[0]\n","        softmax_outputs = self.log_softmax(inputs)\n","        outputs = softmax_outputs[range(batch_size), targets]        \n","        return -torch.sum(outputs)/num_examples\n","\n","    @staticmethod\n","    def log_softmax(x):\n","      return torch.log(torch.exp(x) / torch.sum(torch.exp(x), dim=1, keepdim=True))"],"metadata":{"id":"sHBy9beNOAQo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["$log(softmax(x))= log({x_j\\over{\\sum^n_{i=1}}exp(x_j)})$"],"metadata":{"id":"aaKuS3pMRgyS"}},{"cell_type":"code","source":["# Step 6 Initialize custom_CrossEntropyLoss loss as criterion\n","criterion1 = custom_CrossEntropyLoss1()  \n","optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  \n","criterion1, optimizer"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cg1Uoj9WOAWI","executionInfo":{"status":"ok","timestamp":1669007450406,"user_tz":-480,"elapsed":7,"user":{"displayName":"CHIA HSING CHONG","userId":"13471313610066442776"}},"outputId":"c5e3aeed-bd79-49c3-bb3f-5fe4f7d0a9ce"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(custom_CrossEntropyLoss1(), SGD (\n"," Parameter Group 0\n","     dampening: 0\n","     foreach: None\n","     lr: 0.001\n","     maximize: False\n","     momentum: 0\n","     nesterov: False\n","     weight_decay: 0\n"," ))"]},"metadata":{},"execution_count":120}]},{"cell_type":"code","source":["# Step 7 Train the model, evaluate it on the testing data and save the model\n","total_step = len(train_loader)\n","for epoch in range(num_epochs):\n","    for i, (images, labels) in enumerate(train_loader):\n","        # Reshape images to (batch_size, input_size)\n","        images = images.reshape(-1, input_size)\n","        \n","        # Forward pass\n","        outputs = model(images)\n","        loss = criterion1(outputs, labels)\n","\n","        # Backward and optimize\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        \n","        if (i+1) % 100 == 0:\n","            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n","                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s9_LLeAEOAch","executionInfo":{"status":"ok","timestamp":1669007487386,"user_tz":-480,"elapsed":36985,"user":{"displayName":"CHIA HSING CHONG","userId":"13471313610066442776"}},"outputId":"ef2d0363-8e79-4043-8a35-1ec9eea99b0f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/5], Step [100/600], Loss: 2.2065\n","Epoch [1/5], Step [200/600], Loss: 2.1111\n","Epoch [1/5], Step [300/600], Loss: 2.0517\n","Epoch [1/5], Step [400/600], Loss: 1.9579\n","Epoch [1/5], Step [500/600], Loss: 1.8812\n","Epoch [1/5], Step [600/600], Loss: 1.7747\n","Epoch [2/5], Step [100/600], Loss: 1.7406\n","Epoch [2/5], Step [200/600], Loss: 1.6943\n","Epoch [2/5], Step [300/600], Loss: 1.6233\n","Epoch [2/5], Step [400/600], Loss: 1.5653\n","Epoch [2/5], Step [500/600], Loss: 1.6057\n","Epoch [2/5], Step [600/600], Loss: 1.5092\n","Epoch [3/5], Step [100/600], Loss: 1.4459\n","Epoch [3/5], Step [200/600], Loss: 1.4133\n","Epoch [3/5], Step [300/600], Loss: 1.3286\n","Epoch [3/5], Step [400/600], Loss: 1.2930\n","Epoch [3/5], Step [500/600], Loss: 1.2208\n","Epoch [3/5], Step [600/600], Loss: 1.2834\n","Epoch [4/5], Step [100/600], Loss: 1.2069\n","Epoch [4/5], Step [200/600], Loss: 1.1171\n","Epoch [4/5], Step [300/600], Loss: 1.1621\n","Epoch [4/5], Step [400/600], Loss: 1.1527\n","Epoch [4/5], Step [500/600], Loss: 1.0997\n","Epoch [4/5], Step [600/600], Loss: 1.1945\n","Epoch [5/5], Step [100/600], Loss: 1.0723\n","Epoch [5/5], Step [200/600], Loss: 1.0969\n","Epoch [5/5], Step [300/600], Loss: 1.1046\n","Epoch [5/5], Step [400/600], Loss: 1.0374\n","Epoch [5/5], Step [500/600], Loss: 1.0657\n","Epoch [5/5], Step [600/600], Loss: 0.9979\n"]}]},{"cell_type":"code","source":["# Test the model\n","# In test phase, we don't need to compute gradients (for memory efficiency)\n","with torch.no_grad():\n","    correct = 0\n","    total = 0\n","    for images, labels in test_loader:\n","        images = images.reshape(-1, input_size)\n","        outputs = model(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum()\n","\n","    print('Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n3CR_qVWkxDM","executionInfo":{"status":"ok","timestamp":1669007488872,"user_tz":-480,"elapsed":1496,"user":{"displayName":"CHIA HSING CHONG","userId":"13471313610066442776"}},"outputId":"9a90ad52-de8b-43f3-87a7-061c5795392f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy of the model on the 10000 test images: 82.62000274658203 %\n"]}]},{"cell_type":"code","source":["# Save the model\n","torch.save(model.state_dict(), 'model1.ckpt') "],"metadata":{"id":"sIFGwg7bltoB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Step 8 Compare the loss computed from torch and the custom loss\n","class custom_CrossEntropyLoss2(nn.Module):\n","    def __init__(self, weight=None, size_average=True):\n","        super(custom_CrossEntropyLoss2, self).__init__()\n","\n","    def forward(self, inputs, targets, smooth=1):      \n","        num_examples = targets.shape[0]\n","        batch_size = inputs.shape[0]\n","        # log_softmax from torch\n","        softmax_outputs = nn.functional.log_softmax(inputs, dim=-1)\n","        outputs = softmax_outputs[range(batch_size), targets]        \n","        return -torch.sum(outputs)/num_examples\n"],"metadata":{"id":"uputClavOAig"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Initialize custom_CrossEntropyLoss loss as criterion\n","criterion2 = custom_CrossEntropyLoss2()  \n","optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  \n","criterion2, optimizer"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wTBAEhhLg0_2","executionInfo":{"status":"ok","timestamp":1669007603958,"user_tz":-480,"elapsed":291,"user":{"displayName":"CHIA HSING CHONG","userId":"13471313610066442776"}},"outputId":"ce509943-6a96-4a35-c28e-f942f22c86ef"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(custom_CrossEntropyLoss2(), SGD (\n"," Parameter Group 0\n","     dampening: 0\n","     foreach: None\n","     lr: 0.001\n","     maximize: False\n","     momentum: 0\n","     nesterov: False\n","     weight_decay: 0\n"," ))"]},"metadata":{},"execution_count":139}]},{"cell_type":"code","source":["# Train the model, evaluate it on the testing data and save the model\n","total_step = len(train_loader)\n","for epoch in range(num_epochs):\n","    for i, (images, labels) in enumerate(train_loader):\n","        # Reshape images to (batch_size, input_size)\n","        images = images.reshape(-1, input_size)\n","        \n","        # Forward pass\n","        outputs = model(images)\n","        loss = criterion2(outputs, labels)\n","\n","        # Backward and optimize\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        \n","        if (i+1) % 100 == 0:\n","            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n","                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sUE6NhR_g1qc","executionInfo":{"status":"ok","timestamp":1669007640828,"user_tz":-480,"elapsed":34759,"user":{"displayName":"CHIA HSING CHONG","userId":"13471313610066442776"}},"outputId":"d5ecf69b-bd0d-435e-b6e8-21815d543177"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/5], Step [100/600], Loss: 2.2157\n","Epoch [1/5], Step [200/600], Loss: 2.1277\n","Epoch [1/5], Step [300/600], Loss: 2.0220\n","Epoch [1/5], Step [400/600], Loss: 1.9589\n","Epoch [1/5], Step [500/600], Loss: 1.8541\n","Epoch [1/5], Step [600/600], Loss: 1.8078\n","Epoch [2/5], Step [100/600], Loss: 1.7048\n","Epoch [2/5], Step [200/600], Loss: 1.7018\n","Epoch [2/5], Step [300/600], Loss: 1.5761\n","Epoch [2/5], Step [400/600], Loss: 1.5658\n","Epoch [2/5], Step [500/600], Loss: 1.5058\n","Epoch [2/5], Step [600/600], Loss: 1.3957\n","Epoch [3/5], Step [100/600], Loss: 1.4469\n","Epoch [3/5], Step [200/600], Loss: 1.3921\n","Epoch [3/5], Step [300/600], Loss: 1.3843\n","Epoch [3/5], Step [400/600], Loss: 1.2880\n","Epoch [3/5], Step [500/600], Loss: 1.2841\n","Epoch [3/5], Step [600/600], Loss: 1.2794\n","Epoch [4/5], Step [100/600], Loss: 1.3404\n","Epoch [4/5], Step [200/600], Loss: 1.1709\n","Epoch [4/5], Step [300/600], Loss: 1.1883\n","Epoch [4/5], Step [400/600], Loss: 1.1779\n","Epoch [4/5], Step [500/600], Loss: 1.1062\n","Epoch [4/5], Step [600/600], Loss: 0.9939\n","Epoch [5/5], Step [100/600], Loss: 0.9891\n","Epoch [5/5], Step [200/600], Loss: 1.0563\n","Epoch [5/5], Step [300/600], Loss: 1.0366\n","Epoch [5/5], Step [400/600], Loss: 0.9786\n","Epoch [5/5], Step [500/600], Loss: 0.9155\n","Epoch [5/5], Step [600/600], Loss: 1.0626\n"]}]},{"cell_type":"code","source":["# Test the model\n","# In test phase, we don't need to compute gradients (for memory efficiency)\n","with torch.no_grad():\n","    correct = 0\n","    total = 0\n","    for images, labels in test_loader:\n","        images = images.reshape(-1, input_size)\n","        outputs = model(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum()\n","\n","    print('Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cvBFFVyAl1el","executionInfo":{"status":"ok","timestamp":1669007647388,"user_tz":-480,"elapsed":1475,"user":{"displayName":"CHIA HSING CHONG","userId":"13471313610066442776"}},"outputId":"a76a3216-ad7b-4c55-9432-a7563afca74c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy of the model on the 10000 test images: 82.41999816894531 %\n"]}]},{"cell_type":"code","source":["# Save the model\n","torch.save(model.state_dict(), 'model2.ckpt') "],"metadata":{"id":"QGcVUWiAlzpe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Comparing the log_softmax from custom definition and the internal log_softmax from torch, it can be seen that both yield almost same accuracy 82% and loss of around 1.0 which is expected given the same mathematical definition. "],"metadata":{"id":"WZwsKwa8tWxe"}},{"cell_type":"markdown","metadata":{"id":"2d7IdSoak0p2"},"source":["# Submission Instructions\n","Once you are finished, follow these steps:\n","\n","Restart the kernel and re-run this notebook from beginning to end by going to Kernel > Restart Kernel and Run All Cells.\n","If this process stops halfway through, that means there was an error. Correct the error and repeat Step 1 until the notebook runs from beginning to end.\n","Double check that there is a number next to each code cell and that these numbers are in order.\n","Then, submit your lab as follows:\n","\n","Go to File > Print > Save as PDF.\n","Double check that the entire notebook, from beginning to end, is in this PDF file. Make sure Solution for Exercise 5 are in for marks. \n","Upload the PDF to Spectrum. "]}]}